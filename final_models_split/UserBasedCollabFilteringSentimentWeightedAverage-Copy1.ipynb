{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e099c65c-6ec6-4af2-ba4d-f51afe3352be",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run helper.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e90215dd-1867-498e-8c9d-87a6db60f181",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer, TfidfTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f210cf56-7a18-4c3a-abd0-379db8032da1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentimentAnalysis:\n",
    "    \n",
    "    def __init__(self, X_train, y_train):\n",
    "        self._pipeline = Pipeline([('vect', CountVectorizer(max_df=0.5, max_features=50000, ngram_range=(1,2))),\n",
    "                     ('tfidf', TfidfTransformer(use_idf=True)),\n",
    "                     ('clf', LogisticRegression(C=100, penalty='l2'))])\n",
    "\n",
    "        self._pipeline.fit(X_train['sentence'], y_train)        \n",
    "    \n",
    "    def predict(self, X):\n",
    "        return self._pipeline.predict(X['sentence'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "679f61c7-baa0-49ab-916b-6c06c5d6e901",
   "metadata": {},
   "outputs": [],
   "source": [
    "class UserCollabSentimentWeightedAverageModel:\n",
    "    \n",
    "    def __init__(self, sa_model, X_train, y_train, similarity='cosine'):\n",
    "        X_train['overall'] = sa_model.predict(X_train)\n",
    "        self._user_product_matrix = pd.crosstab(X_train.reviewerID, X_train.asin, X_train.overall, aggfunc='max')\n",
    "        \n",
    "        if similarity == 'cosine': \n",
    "            cos_similarity = cosine_similarity(self._user_product_matrix.copy().fillna(0))\n",
    "            self._similarity = pd.DataFrame(cos_similarity, index=self._user_product_matrix.index)\n",
    "            self._similarity.columns = self._user_product_matrix.index\n",
    "        elif similarity == 'pearson':\n",
    "            pea_similarity = np.corrcoef(self._user_product_matrix.copy().fillna(0))\n",
    "            self._similarity = pd.DataFrame(pea_similarity, index=self._user_product_matrix.index)\n",
    "            self._similarity.columns = self._user_product_matrix.index\n",
    "        else:\n",
    "            raise Exception\n",
    "    \n",
    "    def predict(self, X):\n",
    "        results = np.array([])\n",
    "        for i, row in X.iterrows():\n",
    "            results = np.append(results, self._predict(row))\n",
    "        return results\n",
    "            \n",
    "    \n",
    "    def _predict(self, X):\n",
    "        if X['asin'] in self._user_product_matrix and X['reviewerID'] in self._user_product_matrix.index:\n",
    "            sim_scores = self._similarity[X['reviewerID']] \n",
    "            ratings_scores = self._user_product_matrix[X['asin']] \n",
    "\n",
    "            index_not_rated = ratings_scores[ratings_scores.isnull()].index\n",
    "            ratings_scores = ratings_scores.dropna()\n",
    "            sim_scores = sim_scores.drop(index_not_rated)\n",
    "\n",
    "            if sim_scores.sum() != 0:\n",
    "                return np.dot(ratings_scores, sim_scores)/sim_scores.sum()\n",
    "        \n",
    "        return 2.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6f4b14b6-209a-4a8e-b093-072fe5afe711",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = load_train(subset_name)\n",
    "X_train_sa, y_train_sa = load_train_sa(subset_name)\n",
    "X_test, y_test = load_test(subset_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "89e9689e-47cf-453d-85a1-552c35c192ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\larsj\\anaconda3\\envs\\thesis\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.7680270968530732\n",
      "MAE: 0.35750279955207165\n",
      "\n",
      "RMSE: 1.1363303884671383\n",
      "MAE: 0.7812746726824031\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sa_model = SentimentAnalysis(X_train_sa, y_train_sa)\n",
    "y_pred_sa = sa_model.predict(X_test)\n",
    "print_score(y_test, y_pred_sa)\n",
    "model = UserCollabSentimentWeightedAverageModel(sa_model, X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "print_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0c05aed0-988c-4934-8236-943fe2ebe6db",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_preds(model, subset_name, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "05cd873a-1eb9-4879-b3a6-d82ca01cef1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run helper.ipynb\n",
    "for u in user_ids:\n",
    "    save_preds(model, subset_name, model.predict(get_user_pred_data(u, subset_name)), f=u)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6b27d71-a889-416b-8c3e-3c381552d6c0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
