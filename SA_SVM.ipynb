{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "b7e4f498",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from nltk.corpus import stopwords, brown\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "from keras.layers import Embedding, LSTM, Dense, Conv1D, MaxPooling1D, Dropout, Activation\n",
    "from keras.models import Sequential\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import gzip\n",
    "import json\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer, TfidfTransformer\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "# Fit and transform the training data to a document-term matrix using TfidfVectorizer \n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import precision_score, recall_score, make_scorer\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "\n",
    "import seaborn as sns\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09df47ba",
   "metadata": {},
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59d66281",
   "metadata": {},
   "source": [
    "data = pd.read_json('AMAZON_FASHION.json', lines=True)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dca6759",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "with gzip.open(os.path.join(f'CDs_and_Vinyl.json.gz')) as f:\n",
    "        for l in f:\n",
    "            data.append(json.loads(l.strip()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8e4209b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba9741d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13af132f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ab0dbd57",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_amount_product_mentions = 20\n",
    "min_amount_user_mentions = 20\n",
    "filtered_df = data[['asin', 'reviewerID', 'overall', 'reviewText']]\n",
    "    \n",
    "filtered_df = filtered_df.drop_duplicates()    \n",
    "filtered_df = filtered_df[filtered_df['asin'].map(filtered_df['asin'].value_counts()) >= min_amount_product_mentions]\n",
    "filtered_df = filtered_df[filtered_df['reviewerID'].map(filtered_df['reviewerID'].value_counts()) >= min_amount_user_mentions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3e811c4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11522\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\emanu\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:5039: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return super().rename(\n"
     ]
    }
   ],
   "source": [
    "df = filtered_df[~filtered_df.reviewText.isna()]\n",
    "df.rename(columns={'reviewText':'sentence'}, inplace=True)\n",
    "print(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "33b43dbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "STOPWORDS = set(stopwords.words('english'))\n",
    "MIN_WORDS = 4\n",
    "MAX_WORDS = 200\n",
    "\n",
    "PATTERN_S = re.compile(\"\\'s\")  # matches `'s` from text  \n",
    "PATTERN_RN = re.compile(\"\\\\r\\\\n\") #matches `\\r` and `\\n`\n",
    "PATTERN_PUNC = re.compile(r\"[^\\w\\s]\") # matches all non 0-9 A-z whitespace \n",
    "\n",
    "def clean_text(text):\n",
    "    \"\"\"\n",
    "    Series of cleaning. String to lower case, remove non words characters and numbers.\n",
    "        text (str): input text\n",
    "    return (str): modified initial text\n",
    "    \"\"\"\n",
    "    text = text.lower()  # lowercase text\n",
    "    text = re.sub(PATTERN_S, ' ', text)\n",
    "    text = re.sub(PATTERN_RN, ' ', text)\n",
    "    text = re.sub(PATTERN_PUNC, ' ', text)\n",
    "    return text\n",
    "\n",
    "def tokenizer(sentence, min_words=MIN_WORDS, max_words=MAX_WORDS, stopwords=STOPWORDS, lemmatize=True):\n",
    "    \"\"\"\n",
    "    Lemmatize, tokenize, crop and remove stop words.\n",
    "    \"\"\"\n",
    "    if lemmatize:\n",
    "        stemmer = WordNetLemmatizer()\n",
    "        tokens = [stemmer.lemmatize(w) for w in word_tokenize(sentence)]\n",
    "    else:\n",
    "        tokens = [w for w in word_tokenize(sentence)]\n",
    "    token = [w for w in tokens if (len(w) > min_words and len(w) < max_words\n",
    "                                                        and w not in stopwords)]\n",
    "    return tokens    \n",
    "\n",
    "\n",
    "def clean_sentences(df):\n",
    "    \"\"\"\n",
    "    Remove irrelavant characters (in new column clean_sentence).\n",
    "    Lemmatize, tokenize words into list of words (in new column tok_lem_sentence).\n",
    "    \"\"\"\n",
    "    print('Cleaning sentences...')\n",
    "    df['clean_sentence'] = df['sentence'].apply(clean_text)\n",
    "    df['tok_lem_sentence'] = df['clean_sentence'].apply(\n",
    "        lambda x: tokenizer(x, min_words=MIN_WORDS, max_words=MAX_WORDS, stopwords=STOPWORDS, lemmatize=True))\n",
    "    return df\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "67e0cf66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaning sentences...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\emanu\\AppData\\Local\\Temp/ipykernel_45576/3648348919.py:41: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['clean_sentence'] = df['sentence'].apply(clean_text)\n",
      "C:\\Users\\emanu\\AppData\\Local\\Temp/ipykernel_45576/3648348919.py:42: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['tok_lem_sentence'] = df['clean_sentence'].apply(\n"
     ]
    }
   ],
   "source": [
    "df = clean_sentences(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1e93818f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11522\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>clean_sentence</th>\n",
       "      <th>tok_lem_sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2218</th>\n",
       "      <td>My babies are big for their age, I have a 3 mo...</td>\n",
       "      <td>my babies are big for their age  i have a 3 mo...</td>\n",
       "      <td>[my, baby, are, big, for, their, age, i, have,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2284</th>\n",
       "      <td>My friend who works on a reservation loved the...</td>\n",
       "      <td>my friend who works on a reservation loved the...</td>\n",
       "      <td>[my, friend, who, work, on, a, reservation, lo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2698</th>\n",
       "      <td>Good</td>\n",
       "      <td>good</td>\n",
       "      <td>[good]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2713</th>\n",
       "      <td>Good for a day</td>\n",
       "      <td>good for a day</td>\n",
       "      <td>[good, for, a, day]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2759</th>\n",
       "      <td>The GF likes these. She can ware them out of t...</td>\n",
       "      <td>the gf likes these  she can ware them out of t...</td>\n",
       "      <td>[the, gf, like, these, she, can, ware, them, o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>882402</th>\n",
       "      <td>Very nice set!! These nose rings looked great ...</td>\n",
       "      <td>very nice set   these nose rings looked great ...</td>\n",
       "      <td>[very, nice, set, these, nose, ring, looked, g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>882509</th>\n",
       "      <td>This shirt is nice.... The material is not to ...</td>\n",
       "      <td>this shirt is nice     the material is not to ...</td>\n",
       "      <td>[this, shirt, is, nice, the, material, is, not...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>882748</th>\n",
       "      <td>These broke really fast. A screw came out the ...</td>\n",
       "      <td>these broke really fast  a screw came out the ...</td>\n",
       "      <td>[these, broke, really, fast, a, screw, came, o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>883160</th>\n",
       "      <td>looks nice</td>\n",
       "      <td>looks nice</td>\n",
       "      <td>[look, nice]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>883590</th>\n",
       "      <td>This is beautiful. Fits as expected. It is ver...</td>\n",
       "      <td>this is beautiful  fits as expected  it is ver...</td>\n",
       "      <td>[this, is, beautiful, fit, a, expected, it, is...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11522 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 sentence  \\\n",
       "2218    My babies are big for their age, I have a 3 mo...   \n",
       "2284    My friend who works on a reservation loved the...   \n",
       "2698                                                 Good   \n",
       "2713                                       Good for a day   \n",
       "2759    The GF likes these. She can ware them out of t...   \n",
       "...                                                   ...   \n",
       "882402  Very nice set!! These nose rings looked great ...   \n",
       "882509  This shirt is nice.... The material is not to ...   \n",
       "882748  These broke really fast. A screw came out the ...   \n",
       "883160                                         looks nice   \n",
       "883590  This is beautiful. Fits as expected. It is ver...   \n",
       "\n",
       "                                           clean_sentence  \\\n",
       "2218    my babies are big for their age  i have a 3 mo...   \n",
       "2284    my friend who works on a reservation loved the...   \n",
       "2698                                                 good   \n",
       "2713                                       good for a day   \n",
       "2759    the gf likes these  she can ware them out of t...   \n",
       "...                                                   ...   \n",
       "882402  very nice set   these nose rings looked great ...   \n",
       "882509  this shirt is nice     the material is not to ...   \n",
       "882748  these broke really fast  a screw came out the ...   \n",
       "883160                                         looks nice   \n",
       "883590  this is beautiful  fits as expected  it is ver...   \n",
       "\n",
       "                                         tok_lem_sentence  \n",
       "2218    [my, baby, are, big, for, their, age, i, have,...  \n",
       "2284    [my, friend, who, work, on, a, reservation, lo...  \n",
       "2698                                               [good]  \n",
       "2713                                  [good, for, a, day]  \n",
       "2759    [the, gf, like, these, she, can, ware, them, o...  \n",
       "...                                                   ...  \n",
       "882402  [very, nice, set, these, nose, ring, looked, g...  \n",
       "882509  [this, shirt, is, nice, the, material, is, not...  \n",
       "882748  [these, broke, really, fast, a, screw, came, o...  \n",
       "883160                                       [look, nice]  \n",
       "883590  [this, is, beautiful, fit, a, expected, it, is...  \n",
       "\n",
       "[11522 rows x 3 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(df))\n",
    "df[['sentence', 'clean_sentence', 'tok_lem_sentence']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4350c524",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df['sentence']\n",
    "y = df['overall']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, stratify=y, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d50f2412",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f4d97d02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.9329565199374099\n",
      "Mean Squared Error 0.8704078680937228\n"
     ]
    }
   ],
   "source": [
    "pipeline = Pipeline([('vect', CountVectorizer()),\n",
    "                     ('tfidf', TfidfTransformer()),\n",
    "                     ('clf', SVC())])\n",
    "\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "y_pred = pipeline.predict(X_test)\n",
    "\n",
    "print(\"RMSE:\", metrics.mean_squared_error(y_test, y_pred, squared=False))\n",
    "print(\"Mean Squared Error\",mean_squared_error(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d87a57f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def review_classification(X, y, model,clf_model):\n",
    "    \n",
    "    X_c = model.fit_transform(X)\n",
    "    #print(X_c)\n",
    "    print('# features: {}'.format(X_c.shape[1]))\n",
    "    X_train, X_test, y_train, y_test =  train_test_split(X_c, y, test_size=0.3, stratify=y, random_state=42)\n",
    "    print('# train records: {}'.format(X_train.shape[0]))\n",
    "    print('# test records: {}'.format(X_test.shape[0]))\n",
    "    \n",
    "    \n",
    "    \n",
    "    clf = clf_model.fit(X_train, y_train)\n",
    "    acc = clf.score(X_test, y_test)\n",
    "    print(\"Mean Squared Error\",mean_squared_error(y_test, y_pred))\n",
    "    print(\"RMSE:\", metrics.mean_squared_error(y_test, y_pred, squared=False))\n",
    "    print ('Model Accuracy: {}'.format(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "2a26f0e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# features: 9084\n",
      "# train records: 8065\n",
      "# test records: 3457\n",
      "Mean Squared Error 0.8704078680937228\n",
      "RMSE: 0.9329565199374099\n",
      "Model Accuracy: 0.6977147816025455\n"
     ]
    }
   ],
   "source": [
    "review_classification(X, y, c, SVC())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "3a0da1fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# features: 9084\n",
      "# train records: 8065\n",
      "# test records: 3457\n",
      "Mean Squared Error 0.8704078680937228\n",
      "RMSE: 0.9329565199374099\n",
      "Model Accuracy: 0.6632918715649407\n"
     ]
    }
   ],
   "source": [
    "review_classification(X, y, c, MultinomialNB())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "86246b23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# features: 9084\n",
      "# train records: 8065\n",
      "# test records: 3457\n",
      "Mean Squared Error 0.8704078680937228\n",
      "RMSE: 0.9329565199374099\n",
      "Model Accuracy: 0.658952849291293\n"
     ]
    }
   ],
   "source": [
    "review_classification(X, y, c, KNeighborsClassifier())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "b18797d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# features: 9084\n",
      "# train records: 8065\n",
      "# test records: 3457\n",
      "Mean Squared Error 0.8704078680937228\n",
      "RMSE: 0.9329565199374099\n",
      "Model Accuracy: 0.7089962395140295\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\emanu\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "review_classification(X, y, c, LogisticRegression())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1af0538b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
