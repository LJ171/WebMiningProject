{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Vincent\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\Vincent\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Vincent\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Vincent\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\Vincent\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "from IPython.display import display\n",
    "\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import re\n",
    "import contractions\n",
    "\n",
    "from nltk.corpus import stopwords, wordnet\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('omw-1.4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_wordnet_pos(tag):\n",
    "    if tag.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    elif tag.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif tag.startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "    elif tag.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "    else:\n",
    "        return wordnet.NOUN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_preprocessing(serie, stop_words=True, lemmatization=True):\n",
    "    # lowercase\n",
    "    serie = serie.map(lambda x: x.lower())   \n",
    "\n",
    "    # remove extra newlines\n",
    "    serie = serie.map(lambda x: re.sub(r'[\\r|\\n|\\r\\n]+', ' ', x))\n",
    "\n",
    "    # remove @tag\n",
    "    serie = serie.map(lambda x: re.sub(r'@[\\S]+', '', x))\n",
    "\n",
    "    # remove URL\n",
    "    serie = serie.map(lambda x: re.sub('https?://[\\S]+', '', x))\n",
    "\n",
    "    # remove contractions\n",
    "    serie = serie.map(lambda x: contractions.fix(x).lower())\n",
    "\n",
    "    # remove hashtag and numbers\n",
    "    serie = serie.map(lambda x: re.sub(\"[^a-zA-Z]\", \" \", x))\n",
    "\n",
    "    # tokenization\n",
    "    serie = serie.map(word_tokenize)\n",
    "\n",
    "    if stop_words:        \n",
    "        # remove stop words\n",
    "        stop_words = set(stopwords.words('english'))\n",
    "        serie = serie.map(lambda x: [word for word in x if word not in stop_words])\n",
    "    \n",
    "    if lemmatization:\n",
    "        # lemmatization    \n",
    "        serie = serie.map(nltk.tag.pos_tag)\n",
    "        serie = serie.map(lambda x: [(word, get_wordnet_pos(pos_tag)) for (word, pos_tag) in x])\n",
    "        wordnet_lemmatizer = WordNetLemmatizer()\n",
    "        serie = serie.map(lambda x: [wordnet_lemmatizer.lemmatize(word, tag) for (word, tag) in x])\n",
    "    \n",
    "    serie = serie.map(lambda x: ' '.join(word for word in x))\n",
    "\n",
    "    return serie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    i agreed this was useful democrats should definitely not vote for joe biden in the primary\n",
      "dtype: object\n",
      "0    i agree this be useful democrat should definitely not vote for joe biden in the primary\n",
      "dtype: object\n",
      "0    agreed useful democrats definitely vote joe biden primary\n",
      "dtype: object\n",
      "0    agree useful democrat definitely vote joe biden primary\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "pd.set_option('max_colwidth', 400)\n",
    "\n",
    "text = \"i agreed. this was useful. democrats should definitely not vote for joe biden in the primary.\"\n",
    "for stop_words in [False, True]:\n",
    "    for lemmatization in [False, True]:\n",
    "        print(text_preprocessing(pd.Series([text]), stop_words=stop_words, lemmatization=lemmatization))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>overall</th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>asin</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>A1D4G1SNUZWQOT</td>\n",
       "      <td>7106116521</td>\n",
       "      <td>Exactly what I needed.</td>\n",
       "      <td>perfect replacements!!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>A3DDWDH9PX2YX2</td>\n",
       "      <td>7106116521</td>\n",
       "      <td>I agree with the other review, the opening is too small.  I almost bent the hook on some very expensive earrings trying to get these up higher than just the end so they're not seen.  Would not buy again but for the price, not sending back.</td>\n",
       "      <td>I agree with the other review, the opening is ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>A2MWC41EW7XL15</td>\n",
       "      <td>7106116521</td>\n",
       "      <td>Love these... I am going to order another pack to keep in work; someone (including myself) is always losing the back to an earring.  I don't understand why all fish hook earrings don't have them.  Just wish that they were a tiny bit longer.  :)</td>\n",
       "      <td>My New 'Friends' !!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>A2UH2QQ275NV45</td>\n",
       "      <td>7106116521</td>\n",
       "      <td>too tiny an opening</td>\n",
       "      <td>Two Stars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>A89F3LQADZBS5</td>\n",
       "      <td>7106116521</td>\n",
       "      <td>Okay</td>\n",
       "      <td>Three Stars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>883631</th>\n",
       "      <td>5</td>\n",
       "      <td>A1ZSB2Q144UTEY</td>\n",
       "      <td>B01HJHTH5U</td>\n",
       "      <td>I absolutely love this dress!!  It's sexy and comfortable.  The split up the back was too much for me, so I had to sew it about 5 inches, but other than that it's perfect!!  I'm about 175 pounds, 5'5, DD and the Large fit great!</td>\n",
       "      <td>I absolutely love this dress</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>883632</th>\n",
       "      <td>5</td>\n",
       "      <td>A2CCDV0J5VB6F2</td>\n",
       "      <td>B01HJHTH5U</td>\n",
       "      <td>I'm 5'6 175lbs. I'm on the tall side. I wear a large and ordered a large and it still has a comfortable amount of room. Not to snug or too loose. Very true to size. Love it</td>\n",
       "      <td>I wear a large and ordered a large and it still has a comfortable amount of room</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>883633</th>\n",
       "      <td>3</td>\n",
       "      <td>A3O90PACS7B61K</td>\n",
       "      <td>B01HJHTH5U</td>\n",
       "      <td>Too big in the chest area!</td>\n",
       "      <td>Three Stars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>883634</th>\n",
       "      <td>3</td>\n",
       "      <td>A2HO94I89U3LNH</td>\n",
       "      <td>B01HJHF97K</td>\n",
       "      <td>Too clear in the back, needs lining</td>\n",
       "      <td>Three Stars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>883635</th>\n",
       "      <td>5</td>\n",
       "      <td>A2RSX9E79DUHRX</td>\n",
       "      <td>B01HJG5NMW</td>\n",
       "      <td>Ordered and was slightly small. Worked with the company and they are graciously sending me a bigger one. The quality is excellent and it is so cute. Exactly as pictured!</td>\n",
       "      <td>The quality is excellent and it is so cute</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>883636 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        overall      reviewerID        asin  \\\n",
       "0             5  A1D4G1SNUZWQOT  7106116521   \n",
       "1             2  A3DDWDH9PX2YX2  7106116521   \n",
       "2             4  A2MWC41EW7XL15  7106116521   \n",
       "3             2  A2UH2QQ275NV45  7106116521   \n",
       "4             3   A89F3LQADZBS5  7106116521   \n",
       "...         ...             ...         ...   \n",
       "883631        5  A1ZSB2Q144UTEY  B01HJHTH5U   \n",
       "883632        5  A2CCDV0J5VB6F2  B01HJHTH5U   \n",
       "883633        3  A3O90PACS7B61K  B01HJHTH5U   \n",
       "883634        3  A2HO94I89U3LNH  B01HJHF97K   \n",
       "883635        5  A2RSX9E79DUHRX  B01HJG5NMW   \n",
       "\n",
       "                                                                                                                                                                                                                                                  reviewText  \\\n",
       "0                                                                                                                                                                                                                                     Exactly what I needed.   \n",
       "1            I agree with the other review, the opening is too small.  I almost bent the hook on some very expensive earrings trying to get these up higher than just the end so they're not seen.  Would not buy again but for the price, not sending back.   \n",
       "2       Love these... I am going to order another pack to keep in work; someone (including myself) is always losing the back to an earring.  I don't understand why all fish hook earrings don't have them.  Just wish that they were a tiny bit longer.  :)   \n",
       "3                                                                                                                                                                                                                                        too tiny an opening   \n",
       "4                                                                                                                                                                                                                                                       Okay   \n",
       "...                                                                                                                                                                                                                                                      ...   \n",
       "883631                  I absolutely love this dress!!  It's sexy and comfortable.  The split up the back was too much for me, so I had to sew it about 5 inches, but other than that it's perfect!!  I'm about 175 pounds, 5'5, DD and the Large fit great!   \n",
       "883632                                                                          I'm 5'6 175lbs. I'm on the tall side. I wear a large and ordered a large and it still has a comfortable amount of room. Not to snug or too loose. Very true to size. Love it   \n",
       "883633                                                                                                                                                                                                                            Too big in the chest area!   \n",
       "883634                                                                                                                                                                                                                   Too clear in the back, needs lining   \n",
       "883635                                                                             Ordered and was slightly small. Worked with the company and they are graciously sending me a bigger one. The quality is excellent and it is so cute. Exactly as pictured!   \n",
       "\n",
       "                                                                                 summary  \n",
       "0                                                                 perfect replacements!!  \n",
       "1                                      I agree with the other review, the opening is ...  \n",
       "2                                                                    My New 'Friends' !!  \n",
       "3                                                                              Two Stars  \n",
       "4                                                                            Three Stars  \n",
       "...                                                                                  ...  \n",
       "883631                                                      I absolutely love this dress  \n",
       "883632  I wear a large and ordered a large and it still has a comfortable amount of room  \n",
       "883633                                                                       Three Stars  \n",
       "883634                                                                       Three Stars  \n",
       "883635                                        The quality is excellent and it is so cute  \n",
       "\n",
       "[883636 rows x 5 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_json('data/AMAZON_FASHION.json', lines=True)\n",
    "data = data[['overall', 'reviewerID', 'asin', 'reviewText', 'summary']]\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "overall        int64\n",
       "reviewerID    object\n",
       "asin          object\n",
       "reviewText    object\n",
       "summary       object\n",
       "dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stop_words: False, lemmatization: False, time: 153.56838274002075\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'i agree with the other review the opening is too small i almost bent the hook on some very expensive earrings trying to get these up higher than just the end so they are not seen would not buy again but for the price not sending back'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stop_words: False, lemmatization: False, time: 73.04949116706848\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'i agree with the other review the opening is'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stop_words: False, lemmatization: True, time: 1867.2276928424835\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'i agree with the other review the opening be too small i almost bend the hook on some very expensive earring try to get these up high than just the end so they be not see would not buy again but for the price not send back'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stop_words: False, lemmatization: True, time: 818.2632191181183\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'i agree with the other review the opening be'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stop_words: True, lemmatization: False, time: 147.93516373634338\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'agree review opening small almost bent hook expensive earrings trying get higher end seen would buy price sending back'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stop_words: True, lemmatization: False, time: 74.64093971252441\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'agree review opening'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stop_words: True, lemmatization: True, time: 1538.4630012512207\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'agree review open small almost bent hook expensive earring try get high end see would buy price send back'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stop_words: True, lemmatization: True, time: 797.4107813835144\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'agree review opening'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for stop_words in [False, True]:\n",
    "    for lemmatization in [False, True]:\n",
    "        unpro_review = data.reviewText.copy()\n",
    "        unpro_summary = data.summary.copy()\n",
    "        \n",
    "        a = time.time()\n",
    "        pro_review = text_preprocessing(unpro_review.astype(str), stop_words=stop_words, lemmatization=lemmatization)\n",
    "        print(f\"stop_words: {stop_words}, lemmatization: {lemmatization}, time: {time.time() - a}\")\n",
    "        display(pro_review[1])\n",
    "        name_file = 'review'\n",
    "        if stop_words:\n",
    "            name_file += '_stop'\n",
    "        if lemmatization:\n",
    "            name_file +='_lem'\n",
    "        pro_review.to_pickle(os.path.join('data', name_file + '.pickle'))\n",
    "        del pro_review\n",
    "        \n",
    "        a = time.time()\n",
    "        pro_summary = text_preprocessing(unpro_summary.astype(str), stop_words=stop_words, lemmatization=lemmatization)\n",
    "        print(f\"stop_words: {stop_words}, lemmatization: {lemmatization}, time: {time.time() - a}\")\n",
    "        display(pro_summary[1])\n",
    "        name_file = 'summary'\n",
    "        if stop_words:\n",
    "            name_file += '_stop'\n",
    "        if lemmatization:\n",
    "            name_file +='_lem'\n",
    "        pro_summary.to_pickle(os.path.join('data', name_file + '.pickle'))\n",
    "        del pro_summary"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
